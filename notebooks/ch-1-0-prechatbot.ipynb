{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatbot using OpenAI's 4.o model. This is a project from `Large Language Models Projects: Apply and Implement Strategies for Large Language Models` by Pere Martra from Apress Books. \n",
    "This is Chapter 1, part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (1.58.1)\n",
      "Requirement already satisfied: python-dotenv in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Collecting panel\n",
      "  Downloading panel-1.5.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Collecting bleach (from panel)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting bokeh<3.7.0,>=3.5.0 (from panel)\n",
      "  Downloading bokeh-3.6.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting linkify-it-py (from panel)\n",
      "  Downloading linkify_it_py-2.0.3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting markdown (from panel)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting markdown-it-py (from panel)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting mdit-py-plugins (from panel)\n",
      "  Downloading mdit_py_plugins-0.4.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from panel) (24.2)\n",
      "Collecting pandas>=1.2 (from panel)\n",
      "  Using cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting param<3.0,>=2.1.0 (from panel)\n",
      "  Downloading param-2.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting pyviz-comms>=2.0.0 (from panel)\n",
      "  Downloading pyviz_comms-3.0.3-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting requests (from panel)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Collecting Jinja2>=2.9 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting contourpy>=1.2 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Using cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting numpy>=1.16 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Downloading numpy-2.2.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting pillow>=7.1.0 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Using cached pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting PyYAML>=3.10 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: tornado>=6.2 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from bokeh<3.7.0,>=3.5.0->panel) (6.4.2)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Downloading xyzservices-2024.9.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: certifi in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from pandas>=1.2->panel) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->panel)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->panel)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Collecting webencodings (from bleach->panel)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting uc-micro-py (from linkify-it-py->panel)\n",
      "  Downloading uc_micro_py-1.0.3-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py->panel)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->panel)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->panel)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=2.9->bokeh<3.7.0,>=3.5.0->panel)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/external/github.com/ematta/llm-projects/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->panel) (1.17.0)\n",
      "Downloading panel-1.5.5-py3-none-any.whl (27.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bokeh-3.6.2-py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "Downloading param-2.2.0-py3-none-any.whl (119 kB)\n",
      "Downloading pyviz_comms-3.0.3-py3-none-any.whl (83 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl (196 kB)\n",
      "Using cached contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading numpy-2.2.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: webencodings, pytz, xyzservices, urllib3, uc-micro-py, tzdata, PyYAML, pillow, param, numpy, mdurl, MarkupSafe, markdown, charset-normalizer, bleach, requests, pyviz-comms, pandas, markdown-it-py, linkify-it-py, Jinja2, contourpy, mdit-py-plugins, bokeh, panel\n",
      "Successfully installed Jinja2-3.1.5 MarkupSafe-3.0.2 PyYAML-6.0.2 bleach-6.2.0 bokeh-3.6.2 charset-normalizer-3.4.1 contourpy-1.3.1 linkify-it-py-2.0.3 markdown-3.7 markdown-it-py-3.0.0 mdit-py-plugins-0.4.2 mdurl-0.1.2 numpy-2.2.1 pandas-2.2.3 panel-1.5.5 param-2.2.0 pillow-11.0.0 pytz-2024.2 pyviz-comms-3.0.3 requests-2.32.3 tzdata-2024.2 uc-micro-py-1.0.3 urllib3-2.3.0 webencodings-0.5.1 xyzservices-2024.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai==1.58.1\n",
    "%pip install python-dotenv panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the OpenAI environment as well as the system prompt. In the prompt, we are an ice cream salesman with several options for sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! Welcome to my ice cream stand! What can I get for you today? Here‚Äôs what we have on the menu:\n",
      "\n",
      "- **Lemon**: $6\n",
      "- **Chocolate**: $7\n",
      "- **Strawberry**: $6\n",
      "\n",
      "Feel free to ask if you need any recommendations! What flavor are you in the mood for? üç¶\n"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Act as an Ice Cream Seller. Ask the customer what they want and offer ice creams on the menu.\n",
    "Ice Creams:\n",
    "Lemon 6\n",
    "Chocolate 7\n",
    "Strawberry 6\n",
    "\"\"\"\n",
    "\n",
    "context = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': system_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=context)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model connection initialized, with a system prompt, we investigate what the prompt is and extend it with more context from user and assistant roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! One lemon ice cream coming right up! That‚Äôll be $6. Would you like it in a cup or a cone? üçãüç¶\n"
     ]
    }
   ],
   "source": [
    "context.append({\n",
    "    'role': 'assistant',\n",
    "    'content': response.choices[0].message.content\n",
    "})\n",
    "\n",
    "context.append({\n",
    "    'role': 'user',\n",
    "    'content': 'A lemon ice cream, please.'\n",
    "})\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=context)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we added context to a conversation by continuously updating the message context. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
